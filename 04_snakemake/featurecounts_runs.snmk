## Snakemake rules related to featurecounts processing
##
## 7th Sept 2021

gtfs_dict = {'count_repeats_on_cellranger_standard' : op.join(config['base'], 'annotation', op.basename(config['rep_gtf_url'])),
             'count_repeats_on_cellranger_repeats' : op.join(config['base'], 'annotation', op.basename(config['rep_gtf_url'])),
             'bowtie_repeatome': op.join(config['base'], 'annotation', 'fake_repeatome_from_' + op.splitext(op.basename(config['rep_gtf_url']))[0]) + '.gtf.gz',
             'count_repeats_on_cellranger_standard_not_overlapping_genes' : op.join(config['base'], 'annotation', op.basename(config['rep_gtf_url']) + '_minus_' + op.basename(config['genes_gtf_url']))}

## for spawned bams (e.g. by cell barcode)
input_flags_dict = {'count_repeats_on_cellranger_standard': op.join(config['base'], "runs", config['run_name'], 'count_repeats_on_cellranger_standard', 'split.flag'),
                    'count_repeats_on_cellranger_standard_not_overlapping_genes': op.join(config['base'], "runs", config['run_name'], 'count_repeats_on_cellranger_standard', 'split.flag'),
                    'count_repeats_on_cellranger_repeats': op.join(config['base'], "runs", config['run_name'], 'count_repeats_on_cellranger_repeats', 'split.flag'),
                    'bowtie_repeatome': op.join(config['base'], "runs", config['run_name'], 'bowtie_repeatome', 'split_bowtie.flag')}
             
def get_gtf_by_task(wildcards):
    return(gtfs_dict[wildcards.task])

def get_input_flag_by_task(wildcards):
    return(input_flags_dict[wildcards.task])  

def get_featurecounts_input_path(wildcards):
    return(op.dirname(input_flags_dict[wildcards.task]))

## as in `get_subset_count_files(wildcards)` to return just one
def get_one_subset_count_file_by_task(wildcards):
    return(get_subset_count_files_by_task(wildcards)[0])

## in a setting with multiple bams -> getting multiple count outputs grouping bams in
##   subsets -> final count table,
##   this lists all the multiple count outputs from a run (to be summarized into a final
##   count table)
def get_subset_count_files_by_task(wildcards):
    res = []
    for subset_id in bam_sets.keys():
        res.append(op.join(config['base'], "runs",
                   config['run_name'],
                           wildcards.task,
                           wildcards.multimappers,
                           subset_id,
                           subset_id + '_' + config['run_name'] + ".counts.gz"))
    return(res)

## this lists all bam files analyzed within a subset, as defined in a dictionary
def list_bams_within_subset(wildcards):
    return(bam_sets[wildcards.bam_subset])

rule featurecounts_in_subsets:
    input:
        flag = get_input_flag_by_task,
        gtf = get_gtf_by_task
    params:
        path = get_featurecounts_input_path,
        output_path = op.join(config['base'], "runs", config['run_name'],
                              '{task}',
                              '{multimappers}',
                              '{bam_subset}'),
        featurecounts = config['software']['featurecounts'],
        pigz = config['software']['pigz'],
        bams = list_bams_within_subset
    output:
        counts  = temp(op.join(config['base'], "runs", config['run_name'],
                               '{task}',
                               '{multimappers}',
                               '{bam_subset}',
                               '{bam_subset}' + '_' + config['run_name'] + ".counts")),
        gz_counts = temp(op.join(config['base'], "runs", config['run_name'],
                                 '{task}',
                                 '{multimappers}',
                                 '{bam_subset}',
                                 '{bam_subset}' + '_' + config['run_name'] + ".counts.gz")),
        summary = temp(op.join(config['base'], "runs", config['run_name'],
                               '{task}',
                               '{multimappers}',
                               '{bam_subset}',
                               '{bam_subset}' + '_' + config['run_name'] + ".counts.summary"))
    log :
        log = op.join(config['base'], "runs",  config['run_name'],
                      '{task}',
                      '{multimappers}',
                      '{bam_subset}',
                      'subset_{bam_subset}_feature_counts.log'),
    threads:
        2
    run:
        if wildcards.multimappers == 'multimappers':
            shell("""
            echo multimappers allowed

            mkdir -p {params.output_path}
            cd {params.path}

            {params.featurecounts} -T {threads} \
            -t exon \
            -g gene_id \
            -a {input.gtf} \
            -o  {output.counts} \
            -M \
            --fraction \
            {params.bams}  &> {log}

            {params.pigz} -f --keep -p {threads} {output.counts} -c > {output.gz_counts}

            """)
        elif wildcards.multimappers == 'unique_reads':
            shell("""
            echo unique only

            mkdir -p {params.output_path}

            cd {params.path}

            {params.featurecounts} -T {threads} \
            -t exon \
            -g gene_id \
            -a {input.gtf} \
            -o  {output.counts} \
            {params.bams}  &> {log}

            {params.pigz} -f --keep -p {threads} {output.counts} -c > {output.gz_counts}
            """)

#featurecounts outputs are:
# Geneid  Chr     Start   End     Strand  Length  bam1 bam2 ... bamn
"""
So we're pasting the first 0,1,2,3,4,5 columns of the first file, to the 6:num_bams+6. 
"""
rule merge_featurecounts_in_chunks_generalized:
    input:
        gz_counts_in_chunks = get_subset_count_files_by_task,
        gz_counts_pivot = get_one_subset_count_file_by_task
    output:
        gz_counts_merged = op.join(config['base'], "runs", config['run_name'],
                            '{task}',
                            '{multimappers}',
                            config['run_name'] + "_TEST2_repeats.counts.gz")
    params:
        path = op.join(config['base'], "runs", config['run_name'],
                       '{task}', 'split'),
        output_path = op.join(config['base'], "runs", config['run_name'],
                              '{task}',
                              '{multimappers}'),
        featurecounts = config['software']['featurecounts'],
        pigz = config['software']['pigz']
    threads:
        config['params']['nthreads']        
    shell:
        """
        command='paste -d"\t"'
        command="$command <({params.pigz} -p {threads} -cd {input.gz_counts_pivot} | cut -f 1-5)"
        
        for i in {input.gz_counts_in_chunks}
        do
           command="$command <(gzip -cd $i | cut -f 6-)"
        done
        
        eval $command | {params.pigz} -p {threads} --to-stdout > {output.gz_counts_merged}
        """
