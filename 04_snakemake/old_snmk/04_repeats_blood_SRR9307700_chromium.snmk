#!/usr/bin/env snakemake -s
## 
## Started 14th Jan 2020
##
## Izaskun Mallona
## GPLv3

print('do not run, there is only an enormous fastq file and not R1, R2 reads')

import os.path as op
from glob import glob

# Single-cell RNA-sequencing of skin, fresh blood, and cultured peripheral blood mononuclear cells
#   from a patient with drug-induced hypersensitivity syndrome and healthy volunteers
  
RUN_NAME  = 'SRR9307700'
# Samples were prepared using 10X Genomics Chromium 5 kit and 3 kit (v2).
# https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3892572
CHEMISTRY = 'SC3Pv2'



#@FIXME to be moved to config, not hardcoded!
BASE = op.join('/home', 'imallona', 'repeats_sc')
NTHREADS = 30
LOCAL_MEM_GB = 100

## @FIXME to be moved to config
GENOME_URL = 'ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz'
# GENES_GTF_URL =  'ftp://ftp.ensembl.org/pub/release-98/gtf/homo_sapiens/Homo_sapiens.GRCh38.98.gtf.gz'
GENES_GTF_URL = 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/gencode.v33.primary_assembly.annotation.gtf.gz'
REP_GTF_URL = 'http://labshare.cshl.edu/shares/mhammelllab/www-data/TEtranscripts/TE_GTF/GRCh38_rmsk_TE.gtf.gz'
# REP_GTF_URL = 'http://labshare.cshl.edu/shares/mhammelllab/www-data/TEtranscripts/TE_GTF/mm10_rmsk_TE.gtf.gz'
DFAM_EMBL_URL = 'https://www.dfam.org/releases/current/families/Dfam.embl.gz'
# TRANSCRIPTOME_URL= 'ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz'
TRANSCRIPTOME_URL = 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/gencode.v33.pc_transcripts.fa.gz'

CELLRANGER_HG38_URL = 'http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-GRCh38-3.0.0.tar.gz'

## @FIXME to be moved to config

GTF_PARSING_RSCRIPT = '~/src/repeats_sc/04_snakemake/gtf_parser.R'

BOWTIE_BUILD = '/home/imallona/soft/bowtie/bowtie-1.2.3/bowtie-build'
BOWTIE = '/home/imallona/soft/bowtie/bowtie-1.2.3/bowtie'

##pigz 2.3.1
PIGZ = '/usr/bin/pigz'
BIOPYTHON_CONVERT='biopython.convert'
STAR = '~/soft/star/STAR-2.7.3a/source/STAR'
FEATURECOUNTS = '~/soft/subread/subread-2.0.0-source/bin/featureCounts'
SALMON = '~/soft/salmon/salmon-1.1.0_linux_x86_64/bin/salmon'
CELLRANGER = '~/soft/cellranger/cellranger-3.1.0/cellranger'
BIOAWK = '~/soft/bioawk/bioawk'
BEDTOOLS = '~/soft/bedtools/bedtools-2.29.2/bin/bedtools'
Rscript = '/usr/local/R/R-3.6.1/bin/Rscript'
FASTQ_DUMP= '~/soft/sra-toools/sratoolkit.2.10.4-ubuntu64/bin/fastq-dump' # fastq-dump : 2.10.4
VDB_VALIDATE = '~/soft/sra-toools/sratoolkit.2.10.4-ubuntu64/bin/vdb-validate'

# print(op.join(BASE, 'data', RUN_NAME))

# samples_R2, = glob_wildcards(op.join(BASE, "data", RUN_NAME, "{sample}_1.fastq.gz"))
# samples_R1, = glob_wildcards(op.join(BASE, "data", RUN_NAME, "{sample}_2.fastq.gz"))
# samples_I3, = glob_wildcards(op.join(BASE, "data", RUN_NAME, "{sample}_3.fastq.gz"))

# ## 
# this is needed to be hardcoded/config file

try:
   if not op.exists(op.dirname(op.join(BASE, 'annotation'))):
      os.makedirs(op.join(BASE, 'annotation'))
except OSError as err:
   print(err)
      
for item in ['bowtie', 'star', 'salmon']:
   try:
      if not op.exists(op.dirname(op.join(BASE, 'indices', item))):
         os.makedirs(op.join(BASE, 'indices', item))
   except OSError as err:
      print(err)
      
## Folder structure end ----------------------------------------------------------------------- ##

rule all:
    input:
        op.join(BASE, 'indices', 'cellranger', 'repeats_hg38', 'Log.out'),
        op.join(BASE, 'runs', RUN_NAME, 'cellranger_standard', 'outs', 'web_summary.html'),
        # op.join(BASE, 'runs', RUN_NAME, 'cellranger_repeats', 'outs', 'web_summary.html'),
        # op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_3.fastq.gz')
        op.join(BASE, "runs", RUN_NAME, 'count_repeats_on_cellranger_standard', RUN_NAME + "_repeats.counts.gz")

# # remeber the readgroup thing!
# rule featurecounts_repeats_repeatome:
#     input:
#         bam = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome", "{fastq}.bam"),
#         gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
#     output:
#         counts  = temp(op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome", "{fastq}.counts")),
#         gz_counts = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome", "{fastq}.counts.gz")
#     log :
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome", "{fastq}_featurecounts.log"),
#     threads:
#         NTHREADS
#     shell:
#        """
#        {FEATURECOUNTS} -T {threads} \
#        -t exon \
#        -g gene_id \
#        -a {input.gtf} \
#        -o  {output.counts} \
#        {input.bam}  2>&1 > {log}

#        {PIGZ} --keep  -p {threads} {output.counts}
#        """

# rule featurecounts_repeats_transcriptome:
#     input:
#         bam = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome', "{fastq}_Aligned.sortedByCoord.out.bam"),
#         gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
#     output:
#         counts  = temp(op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "star_transcriptome", "{fastq}_repeats.counts")),
#         gz_counts = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "star_transcriptome", "{fastq}_repeats.counts.gz")
#     log :
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "star_transcriptome", "{fastq}_repeats_featurecounts.log"),
#     threads:
#         NTHREADS
#     shell:
#        """
#        {FEATURECOUNTS} -T {threads} \
#        -t exon \
#        -g gene_id \
#        -a {input.gtf} \
#        -o  {output.counts} \
#        {input.bam}  2>&1 > {log}

#        {PIGZ} --keep -p {threads} {output.counts}
#        """
       
# rule featurecounts_genes_transcriptome:
#     input:
#         bam = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome', "{fastq}_Aligned.sortedByCoord.out.bam"),
#         gtf = op.join(BASE, 'annotation', op.basename(GENES_GTF_URL))
#     output:
#         counts  = temp(op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "star_transcriptome",
#                           "{fastq}_genes.counts")),
#         gz_counts = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "star_transcriptome",
#                           "{fastq}_genes.counts.gz")
#     log :
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome', "{fastq}_genes_featurecounts.log"),
#     threads:
#         NTHREADS
#     shell:
#        """
#        {FEATURECOUNTS} -T {threads} \
#        -t exon \
#        -g gene_id \
#        -a {input.gtf} \
#        -o  {output.counts} \
#        {input.bam}  2>&1 > {log}

#        {PIGZ} --keep -p {threads} {output.counts}
#        """

## Mapping start ------------------------------------------------------------------------------ ##

# rule map_star_naive:

# rule map_alevin:

# #@untested @todo @current
# ## fix to take into account the different indices to map against
# ## fix the cutadapt sickle thing
# rule map_star_transcriptome_se:
#     input:
#         star_index_flag = op.join(BASE, 'indices', 'star', 'transcriptome', 'chrName.txt'), 
#         fastq = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "{fastq}.fastq.gz")
#     params:
#         star_index = op.join(BASE, 'indices', 'star', 'transcriptome'),
#         path = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome'),
#         prefix = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome', "{fastq}_")
#     output:
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome', "{fastq}_Aligned.sortedByCoord.out.bam")
#     threads:
#         NTHREADS
#     log:
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', 'star_transcriptome', "{fastq}_star.log")
#     # benchmark:
#     #     op.join(BASE, 'run/{sample}/{sample}_star_benchmark.txt')
#     shell:
#         """
#         mkdir -p {params.path}
#         cd {params.path}
        
#         {STAR} --genomeDir {params.star_index} \
#         --readFilesIn {input.fastq} \
#         --runThreadN {threads} \
#         --outFileNamePrefix {params.prefix} \
#         --outSAMtype BAM SortedByCoordinate \
#         --readFilesCommand zcat  
#         """


# rule run_bowtie_repeatome:
#     params:
#         repeatome = op.join(BASE, 'indices', 'bowtie', 'repeatome', op.splitext(op.basename(REP_GTF_URL))[0]),
#         sample = 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14',
#         path = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome")
#     input:
#         fastq = op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "{fastq}.fastq.gz"),
#         repeatome_tag_file = op.join(BASE, 'indices', 'bowtie', 'repeatome', op.splitext(op.basename(REP_GTF_URL))[0] + '.1.ebwt')
#     output:
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome", "{fastq}.bam")
#     log:
#         op.join(BASE, "runs", 'P6_Dbx1_1-8_Np73_9-16_Wnt3a_17-24_CrexAi14', "bowtie_repeatome", "{fastq}_bowtie_repeatome.log")
#     threads :
#         NTHREADS
#     shell:
#         """
#         mkdir -p {params.path}

#         ( {PIGZ} --to-stdout --decompress {input.fastq} | {BOWTIE} -q \
#         -v 2 \
#         --threads {threads} \
#         -k 2 --best --strata \
#         --sam \
#         --chunkmbs 128 {params.repeatome} - |  samtools view -@ {threads} -bS - > {output} ) 2> {log}
#         """





rule rename_data:
    input:
        a1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_1.fastq.gz'),
        a2 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_2.fastq.gz'),
        a3 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_3.fastq.gz')
    params:
        path = op.join(BASE, 'data', RUN_NAME),
        run_name = RUN_NAME   
    output:
        r1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_R1_001.fastq.gz'),
        r2 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_R2_001.fastq.gz'),
        i1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_I1_001.fastq.gz')
    shell:
        """
        cd {params.path}
        ln -s {input.a1} {output.r1}
        ln -s {input.a2} {output.r2}
        ln -s {input.a3} {output.i1}
        """
    
rule split_data:
    input:
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '.fastq.gz')
    params:
        path = op.join(BASE, 'data', RUN_NAME),
        run_name = RUN_NAME
    threads:
        NTHREADS
    output:
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_1.fastq.gz'),
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_2.fastq.gz'),
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_3.fastq.gz')
    log:
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_split.log')
    shell:
        """
        cd {params.path}
        
        ## {VDB_VALIDATE} {params.run_name}
        ## {FASTQ_DUMP} -I --gzip --split-files {params.run_name}

        ## very dirty approach, should rather use awk and read the file once, not three times

       {PIGZ} -p {threads} --to-stdout --decompress {input}  | \
        tee >( grep -A 3 "@SRR9307700.3" | {PIGZ} -p {threads} --to-stdout  > {params.run_name}_3.fastq.gz ) \
        | tee >( grep -A 3 "@SRR9307700.2" | {PIGZ} -p {threads} --to-stdout  > {params.run_name}_2.fastq.gz ) \
        | tee >(  grep -A 3 "@SRR9307700.1" | {PIGZ} -p {threads} --to-stdout  > {params.run_name}_1.fastq.gz ) &> /dev/null

        # {PIGZ} -p {threads} --to-stdout --decompress {input} | grep -A 3 "/3$" | {PIGZ} -p {threads} --to-stdout > {params.run_name}_3.fastq.gz

        # {PIGZ} -p {threads} --to-stdout --decompress {input} | grep -A 3 "/2$" | {PIGZ} -p {threads} --to-stdout > {params.run_name}_2.fastq.gz

        # {PIGZ} -p {threads} --to-stdout --decompress {input} | grep -A 3 "/1$" | {PIGZ} -p {threads} --to-stdout > {params.run_name}_1.fastq.gz


        """
    
rule get_data:
    output:
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '.fastq.gz')
    params:
        path = op.join(BASE, 'data', RUN_NAME),
        url = 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR930/000/SRR9307700/SRR9307700.fastq.gz'
        
    log:
        op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_retrieval.log')
    shell:
        """
        mkdir -p {params.path}
        cd $_
        wget {params.url} &> {log}
        """

rule featurecounts_repeats_on_cellranger_standard:
    input:
        flag = op.join(BASE, 'runs', RUN_NAME, 'cellranger_standard', 'outs', 'web_summary.html'),
        bam = op.join(BASE, 'runs', RUN_NAME, 'cellranger_standard', 'outs', 'possorted_genome_bam.bam'),
        gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
    params:
        path = op.join(BASE, "runs", RUN_NAME, 'count_repeats_on_cellranger_standard')
    output:
        counts  = temp(op.join(BASE, "runs", RUN_NAME, 'count_repeats_on_cellranger_standard',
                               RUN_NAME + "_repeats.counts")),
        gz_counts = op.join(BASE, "runs", RUN_NAME, 'count_repeats_on_cellranger_standard',
                               RUN_NAME + "_repeats.counts.gz")
    log :
        op.join(BASE, "runs",  RUN_NAME, 'count_repeats_on_cellranger_standard', "repeats_counts.log")
    threads:
        NTHREADS
    shell:
       """

       mkdir -p {params.path}
       cd $_

       {FEATURECOUNTS} -T {threads} \
       -t exon \
       -g gene_id \
       -a {input.gtf} \
       -o  {output.counts} \
       {input.bam}  2>&1 > {log}

       {PIGZ} --keep -p {threads} {output.counts}
       """

        
rule run_cellranger_repeats:
    input:
        r1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_R1_001.fastq.gz'),
        r2 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_R2_001.fastq.gz'),
        i1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_I1_001.fastq.gz'),       
        transcriptome = op.join(BASE, 'indices', 'cellranger', 'repeats_hg38', 'repeats_hg38')
    params:
        fastqs_path = op.join(BASE, 'data', RUN_NAME),
        sample_name = RUN_NAME,
        local_mem_gb = LOCAL_MEM_GB,
        processing_path = op.join(BASE, 'runs', RUN_NAME),
        chemistry = CHEMISTRY
    output:
        op.join(BASE, 'runs', RUN_NAME, 'cellranger_repeats', 'outs', 'web_summary.html')
    threads:
        NTHREADS
    log:
        op.join(BASE, 'runs', RUN_NAME, 'run_cellranger_repeats.log')
    shell:
        """
        mkdir -p {params.processing_path}
        cd {params.processing_path}
        rm -rf cellranger_repeats

        {CELLRANGER} count --id=cellranger_repeats \
          --fastqs={params.fastqs_path} \
          --transcriptome={input.transcriptome} \
          --jobmode=local \
          --localcores={threads} \
          --sample={params.sample_name} \
          --localmem={params.local_mem_gb} \
          --chemistry={params.chemistry}
        """
        
rule run_cellranger_standard:
    input:
        r1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_R1_001.fastq.gz'),
        r2 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_R2_001.fastq.gz'),
        i1 = op.join(BASE, 'data', RUN_NAME, RUN_NAME + '_S1_L001_I1_001.fastq.gz'),  
        transcriptome = op.join(BASE, 'indices', 'cellranger', 'refdata-cellranger-GRCh38-3.0.0')
    params:
        fastqs_path = op.join(BASE, 'data', RUN_NAME),
        sample_name = RUN_NAME,
        local_mem_gb = LOCAL_MEM_GB,
        processing_path = op.join(BASE, 'runs', RUN_NAME),
        chemistry = CHEMISTRY
    output:
        html = op.join(BASE, 'runs', RUN_NAME, 'cellranger_standard', 'outs', 'web_summary.html'),
        bam = op.join(BASE, 'runs', RUN_NAME, 'cellranger_standard', 'outs', 'possorted_genome_bam.bam')
    threads:
        NTHREADS
    log:
        op.join(BASE, 'runs',  RUN_NAME, 'run_cellranger_standard.log')
    shell:
        """
        mkdir -p {params.processing_path}
        cd {params.processing_path}
        rm -rf cellranger_standard

        {CELLRANGER} count --id=cellranger_standard \
          --fastqs={params.fastqs_path} \
          --transcriptome={input.transcriptome} \
          --jobmode=local \
          --localcores={threads} \
          --sample={params.sample_name} \
          --localmem={params.local_mem_gb} \
          --chemistry={params.chemistry}
        """

# # from https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001
# ## and https://github.com/COMBINE-lab/salmon/issues/336 to get the `attribute` instead of
# ##   the group
# rule get_txp2gene_gene:
#     input:
#         genes_gtf = op.join(BASE, 'annotation', op.basename(GENES_GTF_URL))
#     output:
#         op.join(BASE, 'indices', 'salmon', 'genes_salmon', 'txp2gene.tsv')
#     shell:
#          """
#          {PIGZ} --decompress -p {threads} -c {input.genes_gtf} | \
#            grep transcript | awk '{{print $12,$10}}' | sed -e 's|"||g' -e 's|;||g' | uniq > {output}
#          """

# ## untested @todo check
# rule get_txp2gene_repeat:
#     input:
#         repeats_gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
#     output:
#         op.join(BASE, 'indices', 'salmon', 'repeats_salmon', 'txp2gene.tsv')
#     params:
#         path = op.join(BASE, 'indices', 'salmon', 'repeats_salmon')
#     shell:
#         """
#         mkdir -p {params.path}
        
#         {PIGZ} --decompress -p {threads} -c {input.repeats_gtf} | grep transcript | \
#         awk '{{print $12,$10}}' | sed -e 's|"||g' -e 's|;||g' | uniq > {output}
#         """

# #@untested @todo
# # -l ISR for both Drop-seq and 10x-v2 chemistry
# # https://salmon.readthedocs.io/en/latest/alevin.html#description-of-important-options
# # tech is either --dropseq / --chromium / --chromiumV3
# # beware of the -keepduplicates
# rule run_salmon_chromium_genes:
#     input:        
#         cb_fq1 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L001_R1_001.fastq.gz'),
#         cb_fq2 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L002_R1_001.fastq.gz'),
#         cb_fq3 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L003_R1_001.fastq.gz'),
#         cb_fq4 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L004_R1_001.fastq.gz'),
#         r_fq1 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L001_R2_001.fastq.gz'),
#         r_fq2 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L002_R2_001.fastq.gz'),
#         r_fq3 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L003_R2_001.fastq.gz'),
#         r_fq4 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L004_R2_001.fastq.gz'),
#         tgmap = op.join(BASE, 'indices', 'salmon', 'genes_salmon', 'txp2gene.tsv'),
#         idx_tracker = op.join(BASE, 'indices', 'salmon', 'genes_salmon', 'duplicate_clusters.tsv')
#     output:
#         op.join(BASE, 'runs', '5k_pbmc_v3_salmon_genes', 'alevin', 'quants_mat.gz')
#     threads:
#         NTHREADS
#     params:
#         processing_path = op.join(BASE, 'runs', '5k_pbmc_v3_salmon_genes'),
#         salmon_idx = op.join(BASE, 'indices', 'salmon', 'genes_salmon')
#     log:
#         op.join(BASE, 'runs', '5k_pbmc_v3_salmon_genes', 'run_salmon_chromium.log')
#     shell:
#         """
#         mkdir -p {params.processing_path}
#         cd {params.processing_path}

#         ({SALMON} alevin \
#          -l ISR \
#          -1 {input.cb_fq1} {input.cb_fq2} {input.cb_fq3} {input.cb_fq4} \
#          -2 {input.r_fq1} {input.r_fq2} {input.r_fq3} {input.r_fq4} \
#          --chromiumV3  \
#          --expectCells 5000 \
#          -i {params.salmon_idx} \
#          -p {threads} -o {params.processing_path} \
#          --tgMap {input.tgmap} ) 2> {log}

#         touch -c {output}
#         """


#         #@untested @todo
# # -l ISR for both Drop-seq and 10x-v2 chemistry
# # https://salmon.readthedocs.io/en/latest/alevin.html#description-of-important-options
# # tech is either --dropseq / --chromium / --chromiumV3
# # beware of the -keepduplicates
# rule run_salmon_chromium_repeats:
#     input:        
#         cb_fq1 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L001_R1_001.fastq.gz'),
#         cb_fq2 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L002_R1_001.fastq.gz'),
#         cb_fq3 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L003_R1_001.fastq.gz'),
#         cb_fq4 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L004_R1_001.fastq.gz'),
#         r_fq1 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L001_R2_001.fastq.gz'),      
#         r_fq2 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L002_R2_001.fastq.gz'),
#         r_fq3 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L003_R2_001.fastq.gz'),
#         r_fq4 = op.join(BASE, 'data', 'pbmc_v3','5k_pbmc_v3_fastqs', '5k_pbmc_v3_S1_L004_R2_001.fastq.gz'),
#         tgmap = op.join(BASE, 'indices', 'salmon', 'repeats_salmon', 'txp2gene.tsv'),
#         idx_tracker = op.join(BASE, 'indices', 'salmon', 'repeats_salmon', 'duplicate_clusters.tsv')
#     output:
#         op.join(BASE, 'runs', '5k_pbmc_v3_salmon_repeats', 'alevin', 'quants_mat.gz')
#     params:
#         processing_path = op.join(BASE, 'runs', '5k_pbmc_v3_salmon_repeats'),
#         salmon_idx = op.join(BASE, 'indices', 'salmon', 'repeats_salmon')
#     threads:
#         NTHREADS
#     log:
#         op.join(BASE, 'runs',  '5k_pbmc_v3_salmon_repeats', 'run_salmon_chromium_repeats.log')
#     shell:
#         """
#     mkdir -p {params.processing_path}
#     cd {params.processing_path}

#     ({SALMON} alevin \
#     -l ISR \
#     -1 {input.cb_fq1} {input.cb_fq2} {input.cb_fq3} {input.cb_fq4} \
#     -2 {input.r_fq1} {input.r_fq2} {input.r_fq3} {input.r_fq4} \
#     --chromiumV3  \
#     --expectCells 5000 \
#     -i {params.salmon_idx} \
#     -p {threads} \
#     -o {params.processing_path} \
#     --tgMap {input.tgmap} ) 2> {log}

#     touch -c {output}
#         """
        
## Mapping end -------------------------------------------------------------------------------- ##


## Data retrieval start ----------------------------------------------------------------------- ##


## colon cancer lines
# rather
# ## PRJNA603489	SAMN13934090	SRS6069782	SRX7639818	SRR10974768	9606	Homo sapiens	NextSeq 500	PAIRED	

# wget ftp.sra.ebi.ac.uk/vol1/fastq/SRR109/068/SRR10974768/SRR10974768_1.fastq.gz &
# wget ftp.sra.ebi.ac.uk/vol1/fastq/SRR109/068/SRR10974768/SRR10974768_2.fastq.gz	&
# wget ftp.sra.ebi.ac.uk/vol1/fastq/SRR109/068/SRR10974768/SRR10974768_3.fastq.gz  &


# ## PRJNA603489	SAMN13934088	SRS6069783	SRX7639819	SRR10974769	9606	Homo sapiens	NextSeq 500	PAIRED	

# wget ftp.sra.ebi.ac.uk/vol1/fastq/SRR109/069/SRR10974769/SRR10974769_1.fastq.gz &
# wget ftp.sra.ebi.ac.uk/vol1/fastq/SRR109/069/SRR10974769/SRR10974769_2.fastq.gz &
# wget ftp.sra.ebi.ac.uk/vol1/fastq/SRR109/069/SRR10974769/SRR10974769_3.fastq.gz

# neither, because the _3 are missing, what about getting the sra?
# wget ftp://ftp.sra.ebi.ac.uk/vol1/srr/SRR109/069/SRR10974769
# wget ftp://ftp.sra.ebi.ac.uk/vol1/srr/SRR109/068/SRR10974768

# and then converting
# ~/soft/sra-toools/sratoolkit.2.10.4-ubuntu64/bin/vdb-validate SRR10974769 && ~/soft/sra-toools/sratoolkit.2.10.4-ubuntu64/bin/fastq-dump -I --gzip --split-files SRR10974769 ;
# ~/soft/sra-toools/sratoolkit.2.10.4-ubuntu64/bin/vdb-validate SRR10974768 && ~/soft/sra-toools/sratoolkit.2.10.4-ubuntu64/bin/fastq-dump -I --gzip --split-files SRR10974768 ;


rule get_colon_cancer_lines_GSE144357:    
    params:
        path = op.join(BASE, 'runs', 'colon_cancer_lines_GSE144357'),
        path_data = op.join(BASE, 'data', 'SRR10974769')
    output:
        op.join(BASE, 'runs', 'colon_cancer_lines_GSE144357', '{srr}_1.fastq.gz')
    shell:
        """
        mkdir -p {params.path}
        cd {params.path}
        {FASTQDUMP} -I --gzip --split-files {wildcards.srr}

        cd {params.path_data}
        ln -s SRR10974769_1.fastq.gz SRR10974769_S1_L001_R2_001.fastq.gz
        ln -s SRR10974769_2.fastq.gz SRR10974769_S1_L001_R1_001.fastq.gz
        ln -s SRR10974769_3.fastq.gz SRR10974769_S1_L001_I1_001.fastq.gz

        """

## @todo move to indices retrieval
rule get_cellranger_grch38_genome:
    params:
        url = 'http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-GRCh38-3.0.0.tar.gz'
    output:
        path = op.join(BASE, 'indices', 'cellranger'),
        fn = op.join(BASE, 'indices', 'cellranger', 'refdata-cellranger-GRCh38-3.0.0.tar.gz'),
        uncompressed = op.join(BASE, 'indices', 'cellranger', 'refdata-cellranger-GRCh38-3.0.0', 'reference.json')
    shell:
        """    
        mkdir -p {output.path}
        cd {output.path}
        curl -s -L -C - {params.url} -O {output.fn}
        tar xzvf {output.fn}
        """
        
# ## check if untar is needed @todo
# rule get_pbmc_v3:
#     params:
#         url = 'http://s3-us-west-2.amazonaws.com/10x.files/samples/cell-exp/3.0.2/5k_pbmc_v3/5k_pbmc_v3_fastqs.tar'
#     output:
#         path = op.join(BASE, 'data', 'pbmc_v3'),
#         fn = op.join(BASE, 'data', 'pbmc_v3', '5k_pbmc_v3_fastqs.tar'),
#         uncompressed =  op.join(BASE, 'data', 'pbmc_v3', '5k_pbmc_v3_fastqs',
#                                 '5k_pbmc_v3_S1_L001_I1_001.fastq.gz')
#     shell:
#         """    
#         mkdir -p {output.path}
#         cd {output.path}
#         curl -s -L -C - {params.url} -O {output.fn}
#         tar xvf {output.fn}
#         """

## Data retrieval end ------------------------------------------------------------------------- ##


## Indexing start ----------------------------------------------------------------------------- ##


rule index_cellranger_repeats:
    input:
       compressed_fa = op.join(BASE, 'annotation', op.basename(GENOME_URL)),
       compressed_gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
    params:
       local_mem_gb = LOCAL_MEM_GB,
       path =  op.join(BASE, 'indices', 'cellranger', 'repeats_hg38'),
       genome = 'repeats_hg38'
    threads:
        NTHREADS
    output:
        uncompressed_gtf = temp(op.join(BASE, 'annotation', op.splitext(op.basename(REP_GTF_URL))[0])),
        flag = op.join(BASE, 'indices', 'cellranger', 'repeats_hg38', 'Log.out'),
        uncompressed_fa = temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENOME_URL))[0]))
    shell:
       """ 
       mkdir -p {params.path}
       cd {params.path}
 
       {PIGZ} --decompress  -p {threads} --keep -c {input.compressed_fa} > \
        {output.uncompressed_fa}

       {PIGZ} --decompress  -p {threads} --keep -c {input.compressed_gtf} > \
         {output.uncompressed_gtf}
       
       {CELLRANGER} mkref --genome {params.genome} \
       --fasta {output.uncompressed_fa} \
       --genes {output.uncompressed_gtf} \
       --nthreads {threads} \
       --memgb {params.local_mem_gb} 

       touch {output.flag}
       """
                                                
rule index_repeats_salmon_no_decoy:
    input:
        repeats = op.join(BASE, 'annotation', 'repeatome_from_' + op.splitext(op.basename(REP_GTF_URL))[0] + '.fa.gz')
    output:
        op.join(BASE, 'indices', 'salmon', 'repeats_salmon', 'duplicate_clusters.tsv'),
        op.join(BASE, 'indices', 'salmon', 'repeats_salmon', 'complete_ref_lens.bin')
    params:
        path = op.join(BASE, 'indices', 'salmon', 'repeats_salmon'),
        k = 31
    threads:
        NTHREADS
    log:
        op.join(BASE, 'indices', 'salmon', 'repeats_salmon_index.log')
    shell:
        """
        mkdir -p {params.path}
        
        ({SALMON} index -p {threads} \
          index -t {input.repeats} -i {params.path} -k {params.k}) 2> {log}
        """


# # https://salmon.readthedocs.io/en/latest/alevin.html
# # ./bin/salmon index -t transcripts.fa -i transcripts_index --decoys decoys.txt -k 31
# ## shall I use a decoy? https://github.com/COMBINE-lab/SalmonTools/README.md
# # apparently not
# # **NOTE:** Salmon version [v1.0](https://github.com/COMBINE-lab/salmon/releases/tag/v1.0.0) can directly index the genome and transcriptome and doesn't mandates to run the `generateDecoyTranscriptome` script, however it's still backward compatible. Please checkout [this](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) tutorial on how to run salmon with full genome + transcriptome without the annotation.
# rule index_genes_salmon_no_decoy:
#     input:
#         transcripts = op.join(BASE, 'annotation', op.basename(TRANSCRIPTOME_URL))
#     params:
#         k = 31,
#         path = op.join(BASE, 'indices', 'salmon', 'genes_salmon')
#     log:
#         op.join(BASE, 'indices', 'salmon', 'genes_salmon', 'genes_salmon_index.log')
#     threads:
#         NTHREADS
#     output:
#         op.join(BASE, 'indices', 'salmon', 'genes_salmon', 'duplicate_clusters.tsv'),
#         op.join(BASE, 'indices', 'salmon', 'genes_salmon', 'complete_ref_lens.bin')
#     shell:        
#         """
#         mkdir -p {params.path}
        
#         ({SALMON} index --gencode -p {threads} index \
#            -t {input.transcripts} -i {params.path} -k {params.k})  2> {log}

#         touch -c {params.path}

#         """

# rule index_repeats_genome_star:
#     params:
#         genome_dir = op.join(BASE, 'indices', 'star', 'repeatome'),
#     input:
#         fa = op.join(BASE, 'annotation', op.basename(GENOME_URL)),
#         gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
#     log:
#         op.join(BASE, 'indices', 'star', 'repeatome', 'repeats_star_index.log')
#     threads:
#         NTHREADS
#     output:
#         op.join(BASE, 'indices', 'star', 'repeatome', 'chrName.txt'),
#         op.join(BASE, 'indices', 'star', 'repeatome', 'chrStart.txt'),
#         op.join(BASE, 'indices', 'star', 'repeatome', 'chrNameLength.txt'),
#         fa_decomp = temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENOME_URL))[0])),
#         gtf_decomp = temp(op.join(BASE, 'annotation', op.splitext(op.basename(REP_GTF_URL))[0]))
#     shell:
#         """
#         mkdir -p {params.genome_dir}

#         {PIGZ} -k --decompress -p {threads} {input.gtf}
#         {PIGZ} -k --decompress -p {threads} {input.fa}

#         ({STAR}  \
#         --runMode genomeGenerate \
#         --runThreadN {threads} \
#         --sjdbGTFfile {output.gtf_decomp} \
#         --genomeDir {params.genome_dir} \
#         --genomeFastaFiles {output.fa_decomp}) 2> {log}

#         touch {output}
#         """

# rule index_genes_genome_star:
#     params:
#         genome_dir = op.join(BASE, 'indices', 'star', 'transcriptome'),
#     input:
#         fa = op.join(BASE, 'annotation', op.basename(GENOME_URL)),
#         gtf = op.join(BASE, 'annotation', op.basename(GENES_GTF_URL))
#     output:    
#         op.join(BASE, 'indices', 'star', 'transcriptome', 'chrName.txt'),
#         op.join(BASE, 'indices', 'star', 'transcriptome', 'chrStart.txt'),
#         op.join(BASE, 'indices', 'star', 'transcriptome', 'chrNameLength.txt'),
#         fa_decomp = temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENOME_URL))[0])),
#         gtf_decomp = temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENES_GTF_URL))[0]))

#     log:
#         op.join(BASE, 'indices', 'star', 'transcriptome', 'genes_star_index.log')
#     threads:
#         NTHREADS
#     shell:
#         """
#         mkdir -p {params.genome_dir}

#         {PIGZ} -k --decompress -p {threads} {input.gtf}
        
#         {PIGZ} -k --decompress -p {threads} {input.fa}

#         ({STAR}  \
#         --runMode genomeGenerate \
#         --runThreadN {threads} \
#         --sjdbGTFfile {output.gtf_decomp} \
#         --genomeDir {params.genome_dir} \
#         --genomeFastaFiles {output.fa_decomp}) 2> {log}

#         touch {output}
#         """

        
# rule bowtie_index_repeatome_bowtie:
#     input:
#         fa = op.join(BASE, 'annotation', 'repeatome_from_' + op.splitext(op.basename(REP_GTF_URL))[0] + '.fa.gz')
#     threads: NTHREADS
#     params:
#         label = op.join(BASE, 'indices', 'bowtie', 'repeatome',  op.splitext(op.basename(REP_GTF_URL))[0]),
#         path =  op.join(BASE, 'indices', 'bowtie', 'repeatome')
#     log:
#         op.join(BASE, 'indices', 'bowtie', 'repeatome', 'bowtie_repeatome.log')
#     output:
#         fa_uncomp = temp(op.join(BASE, 'annotation', 'repeatome_from_' + op.splitext(op.basename(REP_GTF_URL))[0] + '.fa')),
#         o1 = op.join(BASE, 'indices', 'bowtie', 'repeatome', op.splitext(op.basename(REP_GTF_URL))[0] + '.1.ebwt') #,
#         # o1 = op.join(BASE, 'indices', 'bowtie', 'repeatome', op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.1.ebwt',
#         # o2 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#         #              op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.2.ebwt',
#         # o3 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#         #              op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.3.ebwt',
#         # o4 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#         #              op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.4.ebwt',
#         # o1rev = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#         #                 op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.rev.1.ebwt',
#         # o2rev = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#         #                 op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.rev.2.ebwt'
#     shell:
#         """
#         mkdir -p {params.path}
        
#         {PIGZ} -k --decompress -p {threads} {input.fa}
        
#         ({BOWTIE_BUILD} {output.fa_uncomp} {params.label} --threads {threads}) 2> {log}
#         """


# rule bowtie_index_repeatome_bowtie_old_embl:
#     stop('here replace this by the most recent repeatome from gtf!')
#     input:
#         fa =  op.join(BASE, 'annotation',
#                       op.splitext(op.basename(DFAM_EMBL_URL))[0] + '.fa.gz')
#     threads: NTHREADS
#     params:
#         label = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                         op.splitext(op.basename(DFAM_EMBL_URL))[0]),
#         path =  op.join(BASE, 'indices', 'bowtie', 'repeatome')
#     log:
#         op.join(BASE, 'indices', 'bowtie', 'repeatome', 'bowtie_repeatome.log')
#     output:
#         o1 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                      op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.1.ebwt',
#         o2 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                      op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.2.ebwt',
#         o3 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                      op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.3.ebwt',
#         o4 = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                      op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.4.ebwt',
#         o1rev = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                         op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.rev.1.ebwt',
#         o2rev = op.join(BASE, 'indices', 'bowtie', 'repeatome',
#                         op.splitext(op.basename(DFAM_EMBL_URL))[0]) + '.rev.2.ebwt'
#     shell:
#         """
#         mkdir -p {params.path}
        
#         ({BOWTIE_BUILD} {input.fa} {params.label} --threads {threads}) 2> {log}
#         """
        
## Indexing end ------------------------------------------------------------------------------- ##

## Genome, transcriptome and repeatome retrieval start ---------------------------------------- ##

# rule uncompress_genome:
#     params:
#         genome_dir = op.join(BASE, 'annotation'),
#     input:
#         fagz = op.join(BASE, 'annotation', op.basename(GENOME_URL))
#     output:
#         temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENOME_URL))[0]))
#     shell:
#         """
#         {PIGZ} -k --decompress -p {threads}  {input.fagz}
#         """
        
# rule compress_repeatome_fasta:
#     input:
#         op.join(BASE, 'annotation',
#                 op.splitext(op.basename(DFAM_EMBL_URL))[0] + '.fa')
#     output:
#         op.join(BASE, 'annotation',
#                 op.splitext(op.basename(DFAM_EMBL_URL))[0] + '.fa.gz')
#     threads: NTHREADS
#     shell:
#         """
#         {PIGZ} -p {threads} {input}
#         """

# rule get_transcriptome_cdna:
#     params:
#         url = TRANSCRIPTOME_URL
#     output:
#         fa = op.join(BASE, 'annotation', op.basename(TRANSCRIPTOME_URL))
#     shell:
#         """    
#         curl -s -L -C - {params.url} -o {output.fa}
#         """

# rule get_repeatome_fasta:
#     priority:
#         99
#     input:
#         # op.join(BASE, 'indices', op.basename(DFAM_EMBL_URL))
#         # HTTP.remote(DFAM_EMBL_URL, keep_local=True)
#         op.join(BASE, 'annotation', op.splitext(op.basename(DFAM_EMBL_URL))[0])
#     output:
#         temp(op.join(BASE, 'annotation',
#                      op.splitext(op.basename(DFAM_EMBL_URL))[0] + '.fa'))
#     # conda:
#     #     "envs/repeats_env.yaml"
#     shell:
#         """
#         {BIOPYTHON_CONVERT} {input} embl {output} fasta
#         """

# rule uncompress_repeatome:
#     input:
#         op.join(BASE, 'annotation', op.basename(DFAM_EMBL_URL))
#     output:
#         temp(op.join(BASE, 'annotation', op.splitext(op.basename(DFAM_EMBL_URL))[0]))
#     threads: NTHREADS
#     shell:
#         """
#         {PIGZ} --decompress -p {threads} {input}
#         """
    
# rule get_repeatome_embl:
#     priority:
#         100
#     params:
#         url = DFAM_EMBL_URL
#     output:
#         temp(op.join(BASE, 'annotation', op.basename(DFAM_EMBL_URL)))

#     shell:
#         """
#         curl -s -L -C - {params.url} -o {output}
#         """

rule extract_repeatome_from_gtf:
    priority: 100
    input:
        genome = op.join(BASE, 'annotation', op.basename(GENOME_URL)),
        gtf = op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
    output:
        genome_uncompressed = temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENOME_URL))[0])) + '.temp_extract',
        fai = temp(op.join(BASE, 'annotation', op.splitext(op.basename(GENOME_URL))[0])) + '.temp_extract.fai',
        fasta = temp(op.join(BASE, 'annotation', 'repeatome_from_' + op.splitext(op.basename(REP_GTF_URL))[0]) + '.fa'),
        gtftemp = op.join(BASE, 'annotation', 'temp_' + op.basename(REP_GTF_URL)),
        fastagz = op.join(BASE, 'annotation', 'repeatome_from_' + op.splitext(op.basename(REP_GTF_URL))[0]) + '.fa.gz'
    params :
        rscript = GTF_PARSING_RSCRIPT
    threads:
        NTHREADS
    shell:
        """
        {PIGZ} --keep --decompress -p {threads} -c  {input.genome} > {output.genome_uncompressed}

        ## faking the GTF to describe the instance and not the 'exon'

        {Rscript} {params.rscript} -g {input.gtf} | {PIGZ} -c -p {threads} > \
          {output.gtftemp}
        
        # {BEDTOOLS} getfasta -name -s -fi {output.fasta} \
        #   -bed {output.gtftemp} -fo {output.fasta}

        {BEDTOOLS} getfasta -name -s -fi {output.genome_uncompressed} \
          -bed {output.gtftemp} -fo {output.fasta}

        ## remove the coordinates appended by bedtools!
        sed 's/:/ /g' {output.fasta} | cut -f1 -d" " | \
          {PIGZ}  -p {threads} -c > {output.fastagz}
        
        """

## hg38 hardcoded
rule get_genome_fasta:
    priority:
        100
    output:
        op.join(BASE, 'annotation', op.basename(GENOME_URL))
    params:
        url = GENOME_URL
    shell:
        """
        curl -s -L -C - {params.url} -o {output}
        """
      
rule get_repeats_gtf:
    priority:
        100
    params:
        url = REP_GTF_URL,
        genome_path = op.join(BASE, 'annotation')
    output:
        op.join(BASE, 'annotation', op.basename(REP_GTF_URL))
    shell:
        """        
        curl -s -L -C - {params.url} -o {output}
        """
        
rule get_genes_gtf:
    priority:
        100
    params:
        url = GENES_GTF_URL
    output:
        gtf = op.join(BASE, 'annotation', op.basename(GENES_GTF_URL))
    shell:
        """    
        curl -s -L -C - {params.url} -o {output.gtf}
        """

rule get_cellranger_data:
    priority:
        100
    params:
        url = CELLRANGER_HG38_URL,
        path = op.join(BASE, 'indices', 'cellranger')
    output:
        cellranger_gz = op.join(BASE, 'indices', 'cellranger', op.basename(CELLRANGER_HG38_URL)),
        uncomp = op.join(BASE, 'indices', 'cellranger', 'refdata-cellranger-GRCh38-3.0.0', 'reference.json')
    shell:
        """
        mkdir -p {params.path}
        cd {params.path}

        curl -s -L -C - {params.url} -o {output.gtf}
        
        tar xzvf {output.cellranger_gz}
        """

## Genome, transcriptome and repeatome retrieval end   ---------------------------------------- ##
